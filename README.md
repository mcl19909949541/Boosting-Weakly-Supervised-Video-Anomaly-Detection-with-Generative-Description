# Boosting-Weakly-Supervised-Video-Anomaly-Detection-with-Generative-Description
Our paper has been accepted by PRCV 2025! This is the official project website of our work: Boosting Weakly Supervised Video Anomaly Detection with Generative Description.

ğŸŒ â€‹â€‹Official Implementationâ€‹â€‹ of our PRCV 2025 paper "Boosting Weakly Supervised Video Anomaly Detection with Generative Description".

This repository contains the code and models for â€‹â€‹DBVADâ€‹â€‹, a novel framework that leverages generative descriptions from large Vision-Language Models (VLMs) as semantic supervision signals to enhance visual feature learning for Weakly Supervised Video Anomaly Detection (WSVAD).

## ğŸ“– Overview
Weakly Supervised Video Anomaly Detection (WSVAD) aims to identify anomalous events in videos using only video-level labels, significantly reducing annotation costs. However, most existing methods rely solely on visual information, neglecting the rich semantic context available in textual descriptions.

To bridge this gap, we propose â€‹â€‹DBVADâ€‹â€‹, a framework that integrates generative descriptions from a large VLM (Qwen2.5-VL) to boost the semantic understanding of visual features. Our key contributions include:

â€‹â€‹1. Key Event Selection Strategy (KESS)â€‹â€‹: Efficiently selects informative frames for accurate description generation.

â€‹â€‹2. Temporal Modeling Module (TMM)â€‹â€‹: Captures multi-scale temporal dependencies via progressive temporal convolutions and graph convolutional networks.

3. â€‹â€‹Semantic Focus Prompt (SFP)â€‹â€‹: Calibrates visual features using label semantics.

4. Description Boosted Module (DBM)â€‹â€‹: Aligns visual features with generated descriptions via contrastive learning.


## ğŸš€ Key Features
The Key Features are following:
â€‹â€‹
1. Generative Supervisionâ€‹â€‹: Uses a large VLM to generate video descriptions as additional supervision.

2. â€‹â€‹Efficient Key Frame Selectionâ€‹â€‹: KESS strategy balances semantic relevance and temporal coverage.
   
3. â€‹â€‹Multi-Scale Temporal Modelingâ€‹â€‹: Combines local and global temporal dependencies.
   
â€‹â€‹4. Cross-Modal Alignmentâ€‹â€‹: Enhances visual features via semantic alignment with text.

â€‹â€‹5. State-of-the-Art Performanceâ€‹â€‹: Achieves superior results on UCF-Crime and XD-Violence benchmarks.

 ![PRCV 2025 poster.png](./PRCV 2025 poster.png)
